{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.model_selection import train_test_split\n\n# Load dataset\ndata = pd.read_csv('Reviews.csv')\n\n# Select relevant columns\nreviews = data[['Text', 'Score']]\n\n# Drop null values\nreviews.dropna(inplace=True)\n\n# Function to clean text\ndef preprocess_text(text):\n    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters and numbers\n    text = text.lower()  # Convert to lowercase\n    text = text.split()  # Tokenize\n    stop_words = set(stopwords.words('english'))\n    text = [word for word in text if word not in stop_words]  # Remove stopwords\n    lemmatizer = WordNetLemmatizer()\n    text = [lemmatizer.lemmatize(word) for word in text]  # Lemmatize\n    return ' '.join(text)\n\n# Apply preprocessing\nreviews['Cleaned_Text'] = reviews['Text'].apply(preprocess_text)\n\n# Label sentiment (1 = positive, 0 = negative)\nreviews['Sentiment'] = reviews['Score'].apply(lambda x: 1 if x > 3 else 0)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\n# Word cloud for positive reviews\npositive_reviews = ' '.join(reviews[reviews['Sentiment'] == 1]['Cleaned_Text'])\nwordcloud = WordCloud(width=800, height=400, background_color='white').generate(positive_reviews)\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.title(\"Word Cloud - Positive Reviews\")\nplt.show()\n\n# Bigram analysis\nfrom sklearn.feature_extraction.text import CountVectorizer\nvectorizer = CountVectorizer(ngram_range=(2, 2), max_features=10)\nbigrams = vectorizer.fit_transform(reviews['Cleaned_Text'])\nbigram_freq = dict(zip(vectorizer.get_feature_names_out(), bigrams.sum(axis=0).tolist()[0]))\nplt.barh(list(bigram_freq.keys()), bigram_freq.values())\nplt.title(\"Top 10 Bigrams\")\nplt.show()\n\n# Sentiment distribution\nreviews['Sentiment'].value_counts().plot(kind='bar', color=['red', 'green'])\nplt.title(\"Sentiment Distribution\")\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from sklearn.feature_extraction.text import TfidfVectorizer\n\n# TF-IDF Vectorization\ntfidf = TfidfVectorizer(max_features=5000)  # Limit to 5000 features\nX = tfidf.fit_transform(reviews['Cleaned_Text'])\ny = reviews['Sentiment']\n\n# Split data into train-test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}